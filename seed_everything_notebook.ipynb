{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seed_everything\n",
    "\n",
    "Comprehensive seeding for reproducible machine learning training across all major frameworks.\n",
    "\n",
    "This notebook consolidates the entire `seed_everything` package into a single file. With a single function call, you can seed:\n",
    "- Python's built-in `random` module\n",
    "- NumPy\n",
    "- PyTorch (CPU + CUDA + cuDNN)\n",
    "- TensorFlow / Keras\n",
    "- JAX\n",
    "- scikit-learn\n",
    "- Distributed training frameworks (torch.distributed, Horovod, DeepSpeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities\n",
    "\n",
    "Utility functions for seed validation and management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Configure logger for the package\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def validate_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Validate that the seed is a non-negative integer within the valid range.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value to validate\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If seed is not an integer\n",
    "        ValueError: If seed is negative or out of valid range\n",
    "    \"\"\"\n",
    "    if not isinstance(seed, int):\n",
    "        raise TypeError(f\"Seed must be an integer, got {type(seed).__name__}\")\n",
    "\n",
    "    if seed < 0:\n",
    "        raise ValueError(f\"Seed must be non-negative, got {seed}\")\n",
    "\n",
    "    # Maximum seed value for most systems (2^32 - 1)\n",
    "    max_seed = 2**32 - 1\n",
    "    if seed > max_seed:\n",
    "        raise ValueError(f\"Seed must be <= {max_seed}, got {seed}\")\n",
    "\n",
    "\n",
    "def get_seed_info() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get information about the current seed state for all detected frameworks.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary containing seed state information for available frameworks\n",
    "    \"\"\"\n",
    "    info = {\n",
    "        \"python_available\": True,\n",
    "        \"numpy_available\": False,\n",
    "        \"torch_available\": False,\n",
    "        \"tensorflow_available\": False,\n",
    "        \"jax_available\": False,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        import numpy as np\n",
    "        info[\"numpy_available\"] = True\n",
    "        info[\"numpy_version\"] = np.__version__\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import torch\n",
    "        info[\"torch_available\"] = True\n",
    "        info[\"torch_version\"] = torch.__version__\n",
    "        info[\"cuda_available\"] = torch.cuda.is_available()\n",
    "        if info[\"cuda_available\"]:\n",
    "            info[\"cuda_device_count\"] = torch.cuda.device_count()\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import tensorflow as tf\n",
    "        info[\"tensorflow_available\"] = True\n",
    "        info[\"tensorflow_version\"] = tf.__version__\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import jax\n",
    "        info[\"jax_available\"] = True\n",
    "        info[\"jax_version\"] = jax.__version__\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "    return info\n",
    "\n",
    "\n",
    "def log_seeding(framework: str, seed: int, warn: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Log seeding operation for a framework.\n",
    "\n",
    "    Args:\n",
    "        framework: Name of the framework being seeded\n",
    "        seed: The seed value used\n",
    "        warn: Whether to emit warnings about potential non-deterministic operations\n",
    "    \"\"\"\n",
    "    logger.info(f\"Seeded {framework} with seed={seed}\")\n",
    "\n",
    "    if warn and framework == \"torch\":\n",
    "        logger.warning(\n",
    "            \"PyTorch seeding configured. Note that some operations may still be non-deterministic. \"\n",
    "            \"See https://pytorch.org/docs/stable/notes/randomness.html for details.\"\n",
    "        )\n",
    "    elif warn and framework == \"tensorflow\":\n",
    "        logger.warning(\n",
    "            \"TensorFlow seeding configured. Some operations may still be non-deterministic. \"\n",
    "            \"See https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Seeding\n",
    "\n",
    "Seed Python's built-in `random` module and set `PYTHONHASHSEED`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def seed_python(seed: int, warn: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Seed Python's built-in random module and set PYTHONHASHSEED.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value (non-negative integer)\n",
    "        warn: Whether to emit warnings (default: True)\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    # Seed the random module\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Set PYTHONHASHSEED environment variable\n",
    "    # Note: This must be set before Python starts to be fully effective,\n",
    "    # but we set it here for subprocess and documentation purposes\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "    log_seeding(\"Python\", seed, warn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Seeding\n",
    "\n",
    "Seed NumPy's random number generator (both legacy and modern Generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def seed_numpy(seed: int, warn: bool = True) -> Optional['np.random.Generator']:\n",
    "    \"\"\"\n",
    "    Seed NumPy's random number generator.\n",
    "\n",
    "    This function seeds both the legacy numpy.random.seed() for backwards compatibility\n",
    "    and creates a modern numpy.random.Generator with PCG64 for new code.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value (non-negative integer)\n",
    "        warn: Whether to emit warnings (default: True)\n",
    "\n",
    "    Returns:\n",
    "        A numpy.random.Generator instance with PCG64\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    # Seed legacy global RNG\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # Create and return a modern Generator instance\n",
    "    rng = np.random.Generator(np.random.PCG64(seed))\n",
    "\n",
    "    log_seeding(\"NumPy\", seed, warn)\n",
    "\n",
    "    return rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Seeding\n",
    "\n",
    "Seed PyTorch for CPU and CUDA devices with optional deterministic configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def seed_torch(\n",
    "    seed: int,\n",
    "    deterministic: bool = True,\n",
    "    benchmark: bool = False,\n",
    "    warn: bool = True\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Seed PyTorch for CPU and CUDA devices with optional deterministic configuration.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value (non-negative integer)\n",
    "        deterministic: If True, configure PyTorch for deterministic operations (default: True)\n",
    "        benchmark: If True, enable cuDNN benchmark mode for performance (default: False)\n",
    "                   Note: benchmark mode may introduce non-determinism\n",
    "        warn: Whether to emit warnings (default: True)\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    # Seed PyTorch CPU\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Seed PyTorch CUDA (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)  # For multi-GPU\n",
    "\n",
    "    # Configure cuDNN for determinism\n",
    "    if hasattr(torch.backends, 'cudnn'):\n",
    "        torch.backends.cudnn.deterministic = deterministic\n",
    "        torch.backends.cudnn.benchmark = benchmark\n",
    "\n",
    "    # Enable deterministic algorithms (PyTorch >= 1.8)\n",
    "    if deterministic and hasattr(torch, 'use_deterministic_algorithms'):\n",
    "        try:\n",
    "            torch.use_deterministic_algorithms(True)\n",
    "        except RuntimeError as e:\n",
    "            # Some operations don't support deterministic mode\n",
    "            if warn:\n",
    "                logger.warning(\n",
    "                    f\"Could not enable torch.use_deterministic_algorithms: {e}. \"\n",
    "                    \"Some operations may still be non-deterministic.\"\n",
    "                )\n",
    "\n",
    "    log_seeding(\"PyTorch\", seed, warn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Seeding\n",
    "\n",
    "Seed TensorFlow and configure for deterministic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def seed_tensorflow(seed: int, deterministic: bool = True, warn: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Seed TensorFlow and configure for deterministic operations.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value (non-negative integer)\n",
    "        deterministic: If True, configure TensorFlow for deterministic operations (default: True)\n",
    "        warn: Whether to emit warnings (default: True)\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    # Seed TensorFlow\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    # Configure for deterministic operations\n",
    "    if deterministic:\n",
    "        os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "        os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "        # For TensorFlow 2.x, also try to enable op determinism\n",
    "        if hasattr(tf.config.experimental, 'enable_op_determinism'):\n",
    "            try:\n",
    "                tf.config.experimental.enable_op_determinism()\n",
    "            except Exception as e:\n",
    "                if warn:\n",
    "                    logger.warning(f\"Could not enable TensorFlow op determinism: {e}\")\n",
    "\n",
    "    log_seeding(\"TensorFlow\", seed, warn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JAX Seeding\n",
    "\n",
    "Create a JAX PRNG key from a given seed. JAX uses explicit PRNG keys instead of global state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.random\n",
    "\n",
    "\n",
    "def seed_jax(seed: int, warn: bool = True) -> Any:\n",
    "    \"\"\"\n",
    "    Create a JAX PRNG key from the given seed.\n",
    "\n",
    "    JAX uses a different random number generation approach than other frameworks.\n",
    "    Instead of global state, it uses explicit PRNG keys that must be passed around.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value (non-negative integer)\n",
    "        warn: Whether to emit warnings (default: True)\n",
    "\n",
    "    Returns:\n",
    "        A JAX PRNG key\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    # Create a PRNG key from the seed\n",
    "    key = jax.random.PRNGKey(seed)\n",
    "\n",
    "    log_seeding(\"JAX\", seed, warn)\n",
    "\n",
    "    return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn Seeding\n",
    "\n",
    "Utilities for seeding scikit-learn estimators with `RandomState`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sklearn_random_state(seed: int, warn: bool = True) -> 'np.random.RandomState':\n",
    "    \"\"\"\n",
    "    Create a numpy RandomState instance for use with scikit-learn estimators.\n",
    "\n",
    "    scikit-learn estimators accept a random_state parameter that can be an integer\n",
    "    or a numpy.random.RandomState instance. This function creates a RandomState\n",
    "    for consistent seeding across sklearn operations.\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value (non-negative integer)\n",
    "        warn: Whether to emit warnings (default: True)\n",
    "\n",
    "    Returns:\n",
    "        A numpy.random.RandomState instance\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    random_state = np.random.RandomState(seed)\n",
    "\n",
    "    log_seeding(\"scikit-learn\", seed, warn)\n",
    "\n",
    "    return random_state\n",
    "\n",
    "\n",
    "def seed_sklearn_estimator(estimator: Any, seed: int) -> Any:\n",
    "    \"\"\"\n",
    "    Set the random_state of a scikit-learn estimator if it has that parameter.\n",
    "\n",
    "    Args:\n",
    "        estimator: A scikit-learn estimator object\n",
    "        seed: The seed value (non-negative integer)\n",
    "\n",
    "    Returns:\n",
    "        The estimator with random_state set (returns original if no random_state parameter)\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    # Try set_params first (most common sklearn pattern)\n",
    "    if hasattr(estimator, 'set_params'):\n",
    "        try:\n",
    "            estimator.set_params(random_state=seed)\n",
    "            return estimator\n",
    "        except (ValueError, TypeError):\n",
    "            # Estimator doesn't have random_state parameter or set_params failed\n",
    "            pass\n",
    "\n",
    "    # Try direct attribute setting (fallback)\n",
    "    if hasattr(estimator, 'random_state'):\n",
    "        try:\n",
    "            estimator.random_state = seed\n",
    "        except AttributeError:\n",
    "            # random_state is a read-only property\n",
    "            pass\n",
    "\n",
    "    return estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Training\n",
    "\n",
    "Distributed training seeding utilities including rank detection, rank-aware seeding, and DataLoader worker initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "\n",
    "def get_rank() -> Optional[int]:\n",
    "    \"\"\"\n",
    "    Get the rank of the current process in distributed training.\n",
    "\n",
    "    Attempts to detect rank from various distributed training frameworks:\n",
    "    - PyTorch Distributed (torch.distributed)\n",
    "    - Horovod\n",
    "    - DeepSpeed\n",
    "    - Environment variables (RANK, LOCAL_RANK, SLURM_PROCID)\n",
    "\n",
    "    Returns:\n",
    "        The rank as an integer, or None if not in distributed mode\n",
    "    \"\"\"\n",
    "    # Try PyTorch distributed\n",
    "    try:\n",
    "        import torch.distributed as dist\n",
    "        if dist.is_available() and dist.is_initialized():\n",
    "            return dist.get_rank()\n",
    "    except (ImportError, RuntimeError):\n",
    "        pass\n",
    "\n",
    "    # Try Horovod\n",
    "    try:\n",
    "        import horovod.torch as hvd\n",
    "        hvd.init()\n",
    "        return hvd.rank()\n",
    "    except (ImportError, ValueError):\n",
    "        pass\n",
    "\n",
    "    # Try DeepSpeed\n",
    "    try:\n",
    "        import deepspeed\n",
    "        if hasattr(deepspeed, 'comm') and deepspeed.comm.is_initialized():\n",
    "            return deepspeed.comm.get_rank()\n",
    "    except (ImportError, AttributeError):\n",
    "        pass\n",
    "\n",
    "    # Try environment variables\n",
    "    for env_var in ['RANK', 'LOCAL_RANK', 'SLURM_PROCID', 'PMI_RANK']:\n",
    "        if env_var in os.environ:\n",
    "            try:\n",
    "                return int(os.environ[env_var])\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def seed_distributed(\n",
    "    seed: int,\n",
    "    rank: Optional[int] = None,\n",
    "    warn: bool = True\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Seed for distributed training with rank-aware seeding.\n",
    "\n",
    "    Each rank/worker gets a deterministic but different seed (base_seed + rank)\n",
    "    to ensure different data ordering per worker while maintaining reproducibility.\n",
    "\n",
    "    Args:\n",
    "        seed: The base seed value (non-negative integer)\n",
    "        rank: The rank of the current process. If None, attempts to auto-detect.\n",
    "        warn: Whether to emit warnings (default: True)\n",
    "\n",
    "    Returns:\n",
    "        The actual seed used (base_seed + rank)\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    # Auto-detect rank if not provided\n",
    "    if rank is None:\n",
    "        rank = get_rank()\n",
    "        if rank is None:\n",
    "            rank = 0  # Default to rank 0 if not in distributed mode\n",
    "\n",
    "    # Compute rank-specific seed\n",
    "    rank_seed = seed + rank\n",
    "\n",
    "    # Ensure rank_seed doesn't overflow\n",
    "    max_seed = 2**32 - 1\n",
    "    if rank_seed > max_seed:\n",
    "        rank_seed = rank_seed % max_seed\n",
    "\n",
    "    log_seeding(f\"Distributed (rank={rank})\", rank_seed, warn)\n",
    "\n",
    "    # Configure NCCL for reproducibility\n",
    "    if 'NCCL_DEBUG' not in os.environ:\n",
    "        os.environ['NCCL_DEBUG'] = 'WARN'\n",
    "\n",
    "    return rank_seed\n",
    "\n",
    "\n",
    "def get_worker_init_fn(base_seed: int = 42) -> Callable[[int], None]:\n",
    "    \"\"\"\n",
    "    Get a worker initialization function for PyTorch DataLoader.\n",
    "\n",
    "    This ensures each DataLoader worker has a deterministic but different seed.\n",
    "    Use this with torch.utils.data.DataLoader(worker_init_fn=...).\n",
    "\n",
    "    Example:\n",
    "        >>> loader = DataLoader(dataset, worker_init_fn=get_worker_init_fn(42))\n",
    "\n",
    "    Args:\n",
    "        base_seed: The base seed value (default: 42)\n",
    "\n",
    "    Returns:\n",
    "        A function that can be used as worker_init_fn for DataLoader\n",
    "    \"\"\"\n",
    "    def _init_fn(worker_id: int) -> None:\n",
    "        \"\"\"Initialize worker with deterministic seed.\"\"\"\n",
    "        # Compute worker-specific seed\n",
    "        worker_seed = base_seed + worker_id\n",
    "\n",
    "        # Seed Python\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "        # Seed NumPy\n",
    "        np.random.seed(worker_seed)\n",
    "\n",
    "        # Seed PyTorch\n",
    "        torch.manual_seed(worker_seed)\n",
    "\n",
    "    return _init_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core: `seed_everything`\n",
    "\n",
    "The main entry point that seeds all available ML frameworks and Python's random module with a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(\n",
    "    seed: int = 42,\n",
    "    deterministic: bool = True,\n",
    "    warn: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Seed all available ML frameworks and Python's random module.\n",
    "\n",
    "    This is the main entry point. It seeds:\n",
    "    - Python's built-in random module and PYTHONHASHSEED\n",
    "    - NumPy\n",
    "    - PyTorch CPU and CUDA\n",
    "    - TensorFlow\n",
    "    - JAX\n",
    "\n",
    "    Args:\n",
    "        seed: The seed value (non-negative integer, default: 42)\n",
    "        deterministic: If True, configure frameworks for deterministic operations (default: True)\n",
    "        warn: Whether to emit warnings about non-deterministic operations (default: True)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with seeding results and JAX PRNG key (if JAX is available)\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If seed is not an integer\n",
    "        ValueError: If seed is negative or out of valid range\n",
    "\n",
    "    Example:\n",
    "        >>> result = seed_everything(42)\n",
    "        >>> print(result)\n",
    "    \"\"\"\n",
    "    validate_seed(seed)\n",
    "\n",
    "    result = {\n",
    "        'seed': seed,\n",
    "        'deterministic': deterministic,\n",
    "    }\n",
    "\n",
    "    # Seed Python standard library\n",
    "    seed_python(seed, warn=warn)\n",
    "    result['python'] = True\n",
    "\n",
    "    # Seed NumPy\n",
    "    numpy_rng = seed_numpy(seed, warn=warn)\n",
    "    result['numpy'] = numpy_rng is not None\n",
    "    if numpy_rng is not None:\n",
    "        result['numpy_rng'] = numpy_rng\n",
    "\n",
    "    # Seed PyTorch\n",
    "    seed_torch(seed, deterministic=deterministic, benchmark=False, warn=warn)\n",
    "    result['torch'] = True\n",
    "    result['torch_cuda'] = torch.cuda.is_available()\n",
    "\n",
    "    # Seed TensorFlow\n",
    "    seed_tensorflow(seed, deterministic=deterministic, warn=warn)\n",
    "    result['tensorflow'] = True\n",
    "\n",
    "    # Seed JAX\n",
    "    jax_key = seed_jax(seed, warn=warn)\n",
    "    result['jax'] = jax_key is not None\n",
    "    if jax_key is not None:\n",
    "        result['jax_key'] = jax_key\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Usage\n",
    "\n",
    "Seed all available frameworks with a single call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed all available frameworks with a single call\n",
    "result = seed_everything(42)\n",
    "\n",
    "# Now all random operations are reproducible\n",
    "print(random.random())       # Reproducible\n",
    "print(np.random.rand())      # Reproducible\n",
    "print(torch.rand(1))         # Reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Framework Availability\n",
    "\n",
    "Get information about which frameworks are installed and their versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = get_seed_info()\n",
    "for key, value in info.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Usage\n",
    "\n",
    "Seed with custom options and check which frameworks were seeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed with custom options\n",
    "result = seed_everything(\n",
    "    seed=42,\n",
    "    deterministic=True,   # Enable deterministic operations (may impact performance)\n",
    "    warn=True             # Emit warnings about potential non-deterministic operations\n",
    ")\n",
    "\n",
    "# Check which frameworks were seeded\n",
    "print(f\"NumPy seeded: {result['numpy']}\")\n",
    "print(f\"PyTorch seeded: {result['torch']}\")\n",
    "print(f\"TensorFlow seeded: {result['tensorflow']}\")\n",
    "\n",
    "# For JAX, you get a PRNG key\n",
    "if result['jax']:\n",
    "    jax_key = result['jax_key']\n",
    "    print(f\"JAX PRNG key: {jax_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Framework Seeding\n",
    "\n",
    "Seed each framework independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed only specific frameworks\n",
    "seed_python(42)\n",
    "seed_numpy(42)\n",
    "seed_torch(42, deterministic=True)\n",
    "seed_tensorflow(42)\n",
    "jax_key = seed_jax(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed Training\n",
    "\n",
    "Use rank-aware seeding for distributed training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically detect rank and seed accordingly\n",
    "seed = seed_distributed(base_seed=42)  # rank 0 gets seed 42, rank 1 gets 43, etc.\n",
    "print(f\"Distributed seed: {seed}\")\n",
    "\n",
    "# Or explicitly specify rank\n",
    "seed = seed_distributed(base_seed=42, rank=3)  # This worker gets seed 45\n",
    "print(f\"Distributed seed (rank 3): {seed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader Worker Seeding (PyTorch)\n",
    "\n",
    "Create a worker initialization function for reproducible data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create a simple dataset for demonstration\n",
    "dataset = TensorDataset(torch.randn(100, 10), torch.randint(0, 2, (100,)))\n",
    "\n",
    "# Create a DataLoader with deterministic worker seeding\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=32,\n",
    "    num_workers=0,  # Set to >0 for multi-worker usage\n",
    "    worker_init_fn=get_worker_init_fn(base_seed=42)\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created with {len(loader)} batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn Support\n",
    "\n",
    "Create `RandomState` instances and seed scikit-learn estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Get a numpy RandomState for sklearn\n",
    "random_state = get_sklearn_random_state(42)\n",
    "print(f\"RandomState: {random_state}\")\n",
    "\n",
    "# Use it with sklearn estimators\n",
    "clf = RandomForestClassifier(random_state=random_state)\n",
    "print(f\"Classifier random_state set: {clf.random_state}\")\n",
    "\n",
    "# Or seed an existing estimator\n",
    "clf2 = RandomForestClassifier()\n",
    "seed_sklearn_estimator(clf2, 42)\n",
    "print(f\"Classifier random_state seeded: {clf2.random_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Validation\n",
    "\n",
    "The `validate_seed` function ensures seed values are valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid seeds\n",
    "validate_seed(0)\n",
    "validate_seed(42)\n",
    "validate_seed(2**32 - 1)\n",
    "print(\"All valid seeds passed!\")\n",
    "\n",
    "# Invalid seeds (will raise errors)\n",
    "try:\n",
    "    validate_seed(-1)\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")\n",
    "\n",
    "try:\n",
    "    validate_seed(\"not_an_int\")\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")\n",
    "\n",
    "try:\n",
    "    validate_seed(2**32)\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
